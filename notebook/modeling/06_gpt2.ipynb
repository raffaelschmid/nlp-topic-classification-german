{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "cdc79c83-60dd-4126-aded-dd8823b1c50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, TFBertModel\n",
    "import tensorflow as tf\n",
    "from pandas import read_parquet, DataFrame, Series, concat, merge, to_numeric\n",
    "from data import file\n",
    "from tqdm import tqdm\n",
    "from preprocessing.categorical import binarizer\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1a75c19-b8a0-414d-8079-fc0f5da186ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply progress bar on pandas operations\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "afb29060-32f8-42dd-ac68-64a1219a0b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-german-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee96e5d5-bec8-487f-a8c9-0e8754b3d560",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = read_parquet(file.news_articles_cleaned_train)\n",
    "data_test = read_parquet(file.news_articles_cleaned_test)\n",
    "data_val = read_parquet(file.news_articles_cleaned_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c2793fd-2bdc-4dc1-b3b7-3c8683b7837e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: (7191, 9) categories: 9\n",
      "test size : (2054, 9) categories: 9\n",
      "val size  : (1028, 9) categories: 9\n"
     ]
    }
   ],
   "source": [
    "print(\"train size:\", data_train.shape, \"categories:\", len(data_train.label.unique()))\n",
    "print(\"test size :\", data_test.shape, \"categories:\", len(data_test.label.unique()))\n",
    "print(\"val size  :\", data_val.shape, \"categories:\", len(data_val.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b1a036f-56bc-4c69-bf66-0f237b876584",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXLEN = 192\n",
    "\n",
    "def tokenize(review):\n",
    "\n",
    "  encoded = tokenizer.encode_plus(\n",
    "      text=review,\n",
    "      add_special_tokens=True,     # Add `[CLS]` and `[SEP]`\n",
    "      max_length=MAXLEN,           # Max length to truncate/pad\n",
    "      padding='max_length',        # Pad sentence to max length\n",
    "      return_attention_mask=False, # attention mask not needed for our task\n",
    "      return_token_type_ids=False,\n",
    "      truncation=True)\n",
    "  return encoded['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d4ee786d-420e-48ad-8ee2-6e858123f2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7191/7191 [00:52<00:00, 135.87it/s]\n"
     ]
    }
   ],
   "source": [
    "data_hf_tokenized_train = concat([data_train, data_train.text_original.progress_map(tokenize).rename('hf_tokenized')], axis=1)\n",
    "data_hf_tokenized_train.to_parquet(path=file.news_articles_hf_tokenized_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cbf5b3f6-0106-477b-8027-257fc1375ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2054/2054 [00:15<00:00, 131.58it/s]\n"
     ]
    }
   ],
   "source": [
    "data_hf_tokenized_test = concat([data_test, data_test.text_original.progress_map(tokenize).rename('hf_tokenized')], axis=1)\n",
    "data_hf_tokenized_test.to_parquet(path=file.news_articles_hf_tokenized_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "593dbaaf-a08c-4594-b4ca-9405b9e21dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1028/1028 [00:07<00:00, 131.21it/s]\n"
     ]
    }
   ],
   "source": [
    "data_hf_tokenized_val = concat([data_val, data_val.text_original.progress_map(tokenize).rename('hf_tokenized')], axis=1)\n",
    "data_hf_tokenized_val.to_parquet(path=file.news_articles_hf_tokenized_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "946ba12e-009d-4057-950e-5335b7e5609f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: (7191, 10) categories: 9\n",
      "test size : (2054, 10) categories: 9\n",
      "val size  : (1028, 10) categories: 9\n"
     ]
    }
   ],
   "source": [
    "hf_data_train = read_parquet(file.news_articles_hf_tokenized_train)\n",
    "hf_data_test = read_parquet(file.news_articles_hf_tokenized_test)\n",
    "hf_data_val = read_parquet(file.news_articles_hf_tokenized_val)\n",
    "\n",
    "print(\"train size:\", hf_data_train.shape, \"categories:\", len(hf_data_train.label.unique()))\n",
    "print(\"test size :\", hf_data_test.shape, \"categories:\", len(hf_data_test.label.unique()))\n",
    "print(\"val size  :\", hf_data_val.shape, \"categories:\", len(hf_data_val.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4da3a779-32db-4924-b2f8-40f30bdf1a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train label size: (7191, 9) categories: 9\n",
      "test label size : (2054, 9) categories: 9\n"
     ]
    }
   ],
   "source": [
    "label_binarizer=binarizer(hf_data_train.label)\n",
    "label_bin_train = label_binarizer.transform(hf_data_train.label)\n",
    "label_bin_test = label_binarizer.transform(hf_data_test.label)\n",
    "\n",
    "print(\"train label size:\", label_bin_train.shape, \"categories:\", len(hf_data_train.label.unique()))\n",
    "print(\"test label size :\", label_bin_test.shape, \"categories:\", len(hf_data_test.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "2bb9bbc8-f870-4519-a3cd-13d0533f0fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "EPOCHS = 8\n",
    "LEARNING_RATE = 1e-5\n",
    "\n",
    "train_dataset = (tf.data.Dataset.from_tensor_slices((hf_data_train.hf_tokenized.map(lambda x:x.tolist()).tolist(), label_bin_train))\n",
    "                .batch(BATCH_SIZE)\n",
    "                .prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "test_dataset = (tf.data.Dataset.from_tensor_slices((hf_data_test.hf_tokenized.map(lambda x:x.tolist()).tolist(), label_bin_test))\n",
    "                .batch(BATCH_SIZE)\n",
    "                .prefetch(tf.data.AUTOTUNE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "085d0686-e7b3-482b-8c0e-861e9c010895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(output_classes, max_len=MAXLEN):\n",
    "    \"\"\" add binary classification to pretrained model\n",
    "    \"\"\"\n",
    "\n",
    "    input_word_ids = tf.keras.layers.Input(\n",
    "        shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\"\n",
    "    )\n",
    "\n",
    "    bert_model = TFBertModel.from_pretrained(\"bert-base-german-cased\")\n",
    "    encoder_outputs = bert_model(input_word_ids)\n",
    "\n",
    "    pooler_output = encoder_outputs[1]\n",
    "    cls_embedding = pooler_output\n",
    "\n",
    "    stack = tf.keras.layers.Dense(output_classes)(cls_embedding)\n",
    "    output = tf.keras.layers.Activation('softmax')(stack)\n",
    "\n",
    "    ##########################\n",
    "    ## YOUR CODE HERE END ##\n",
    "    ##########################\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=input_word_ids, outputs=output)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6d07e130-cf5d-4d31-a77b-be6b9e81e54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_word_ids (InputLayer)  [(None, 192)]             0         \n",
      "_________________________________________________________________\n",
      "tf_bert_model_2 (TFBertModel TFBaseModelOutputWithPool 109081344 \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 9)                 6921      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 109,088,265\n",
      "Trainable params: 109,088,265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(len(data_train.label.unique()), max_len=MAXLEN)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "3ba58758-439f-4251-bc3d-0d165b287d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "loss = loss=\"binary_crossentropy\"\n",
    "\n",
    "model.compile(optimizer, loss=loss, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "21d8e92d-4278-4899-98f4-c14e91e17f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 03:13:21.841382: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-11-18 03:13:21.841453: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2021-11-18 03:13:21.843414: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1614] Profiler found 1 GPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 03:13:22.055247: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2021-11-18 03:13:22.055523: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1748] CUPTI activity buffer flushed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 03:13:31.996048: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/449 [..............................] - ETA: 1:41:48 - loss: 0.8372 - accuracy: 0.1250"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 03:13:36.235612: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-11-18 03:13:36.235663: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/449 [..............................] - ETA: 9:03 - loss: 0.8085 - accuracy: 0.1562   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 03:13:37.085122: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2021-11-18 03:13:37.088283: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1748] CUPTI activity buffer flushed\n",
      "2021-11-18 03:13:37.250628: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 3002 callback api events and 2999 activity events. \n",
      "2021-11-18 03:13:37.322504: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2021-11-18 03:13:37.434825: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/2021-11-18 03:13:21.838630/train/plugins/profile/2021_11_18_03_13_37\n",
      "\n",
      "2021-11-18 03:13:37.492466: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to logs/2021-11-18 03:13:21.838630/train/plugins/profile/2021_11_18_03_13_37/frankfurt-tf-26-cpu-2-gpu-1.trace.json.gz\n",
      "2021-11-18 03:13:37.622614: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/2021-11-18 03:13:21.838630/train/plugins/profile/2021_11_18_03_13_37\n",
      "\n",
      "2021-11-18 03:13:37.632529: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to logs/2021-11-18 03:13:21.838630/train/plugins/profile/2021_11_18_03_13_37/frankfurt-tf-26-cpu-2-gpu-1.memory_profile.json.gz\n",
      "2021-11-18 03:13:37.637364: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/2021-11-18 03:13:21.838630/train/plugins/profile/2021_11_18_03_13_37\n",
      "Dumped tool data for xplane.pb to logs/2021-11-18 03:13:21.838630/train/plugins/profile/2021_11_18_03_13_37/frankfurt-tf-26-cpu-2-gpu-1.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs/2021-11-18 03:13:21.838630/train/plugins/profile/2021_11_18_03_13_37/frankfurt-tf-26-cpu-2-gpu-1.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/2021-11-18 03:13:21.838630/train/plugins/profile/2021_11_18_03_13_37/frankfurt-tf-26-cpu-2-gpu-1.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/2021-11-18 03:13:21.838630/train/plugins/profile/2021_11_18_03_13_37/frankfurt-tf-26-cpu-2-gpu-1.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/2021-11-18 03:13:21.838630/train/plugins/profile/2021_11_18_03_13_37/frankfurt-tf-26-cpu-2-gpu-1.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "449/449 [==============================] - 349s 749ms/step - loss: 0.1465 - accuracy: 0.7666 - val_loss: 0.0774 - val_accuracy: 0.8749\n",
      "Epoch 2/8\n",
      "  1/449 [..............................] - ETA: 2:19 - loss: 0.1105 - accuracy: 0.7143WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 3592 batches). You may need to use the repeat() function when building your dataset.\n",
      "449/449 [==============================] - 29s 64ms/step - loss: 0.1105 - accuracy: 0.7143 - val_loss: 0.0782 - val_accuracy: 0.8768\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00002: early stopping\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=int(np.floor((len(hf_data_train) / BATCH_SIZE))),\n",
    "    validation_data=test_dataset,\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "               tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", verbose=1, patience=1, restore_best_weights=True),\n",
    "               tf.keras.callbacks.TensorBoard(f'logs/{datetime.now()}')\n",
    "               ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "42d37d56-1a78-4155-a257-34037f8b682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = data_hf_tokenized_val[0:100]\n",
    "y_predict = label_binarizer.inverse_transform(model.predict(sample.hf_tokenized.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "82ef46a3-5b38-4c35-8933-f375bd8b631e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22732/1953960971.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mreporting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "from reporting.evaluation import plot_confusion_matrix\n",
    "plot_confusion_matrix(data_hf_tokenized_val[0:100], y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "ce1a5591-3493-4cac-a1b0-d29ce6dd28c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_original</th>\n",
       "      <th>label</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>text_tokenized_keywords</th>\n",
       "      <th>text_keywords</th>\n",
       "      <th>text_tokenized_lemmas</th>\n",
       "      <th>text_lemmas</th>\n",
       "      <th>text_tokenized_stemmed</th>\n",
       "      <th>text_stem</th>\n",
       "      <th>hf_tokenized</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9073</th>\n",
       "      <td>1556 – Der Erzbischof von Canterbury, Thomas C...</td>\n",
       "      <td>Wissenschaft</td>\n",
       "      <td>[1556, –, der, erzbischof, von, canterbury, ,,...</td>\n",
       "      <td>[1556, –, erzbischof, canterbury, ,, thomas, c...</td>\n",
       "      <td>1556 – erzbischof canterbury , thomas cranmer ...</td>\n",
       "      <td>[1556, erzbischof, canterbury, thomas, cranmer...</td>\n",
       "      <td>1556 erzbischof canterbury thomas cranmer oxfo...</td>\n",
       "      <td>[1556, erzbischof, canterbury, thomas, cranm, ...</td>\n",
       "      <td>1556 erzbischof canterbury thomas cranm oxford...</td>\n",
       "      <td>[3, 19041, 26960, 2, 233, 9443, 88, 21447, 756...</td>\n",
       "      <td>International</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8537</th>\n",
       "      <td>Gemma Bundesheer schauen! Nationalfeiertag auf...</td>\n",
       "      <td>Inland</td>\n",
       "      <td>[gemma, bundesheer, schauen, !, nationalfeiert...</td>\n",
       "      <td>[gemma, bundesheer, schauen, !, nationalfeiert...</td>\n",
       "      <td>gemma bundesheer schauen ! nationalfeiertag he...</td>\n",
       "      <td>[gemma, bundesheer, schauen, nationalfeiertag,...</td>\n",
       "      <td>gemma bundesheer schauen nationalfeiertag held...</td>\n",
       "      <td>[gemma, bundeshe, schau, nationalfeiertag, hel...</td>\n",
       "      <td>gemma bundeshe schau nationalfeiertag heldenpl...</td>\n",
       "      <td>[3, 610, 751, 578, 14986, 17036, 26982, 1921, ...</td>\n",
       "      <td>Panorama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4544</th>\n",
       "      <td>Am Montag wurde Insolvenz angemeldet. Georg Pf...</td>\n",
       "      <td>Wirtschaft</td>\n",
       "      <td>[am, montag, wurde, insolvenz, angemeldet, ., ...</td>\n",
       "      <td>[montag, wurde, insolvenz, angemeldet, ., geor...</td>\n",
       "      <td>montag wurde insolvenz angemeldet . georg pfei...</td>\n",
       "      <td>[montag, werden, insolvenz, anmelden, georg, p...</td>\n",
       "      <td>montag werden insolvenz anmelden georg pfeiffe...</td>\n",
       "      <td>[montag, wurd, insolvenz, angemeldet, georg, p...</td>\n",
       "      <td>montag wurd insolvenz angemeldet georg pfeiff ...</td>\n",
       "      <td>[3, 570, 4141, 192, 4461, 20095, 26914, 3578, ...</td>\n",
       "      <td>Wirtschaft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547</th>\n",
       "      <td>Drei Fragen in zweifelhafter Nachrichtenumgebu...</td>\n",
       "      <td>Inland</td>\n",
       "      <td>[drei, fragen, in, zweifelhafter, nachrichtenu...</td>\n",
       "      <td>[drei, fragen, zweifelhafter, nachrichtenumgeb...</td>\n",
       "      <td>drei fragen zweifelhafter nachrichtenumgebung ...</td>\n",
       "      <td>[drei, fragen, zweifelhaft, nachrichtenumgebun...</td>\n",
       "      <td>drei fragen zweifelhaft nachrichtenumgebung fp...</td>\n",
       "      <td>[drei, frag, zweifelhaft, nachrichtenumgeb, fp...</td>\n",
       "      <td>drei frag zweifelhaft nachrichtenumgeb fpo-kan...</td>\n",
       "      <td>[3, 2955, 4168, 50, 21618, 6, 4663, 107, 4209,...</td>\n",
       "      <td>Etat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954</th>\n",
       "      <td>Wellenförmige Muster in Materiescheibe um AU M...</td>\n",
       "      <td>Wissenschaft</td>\n",
       "      <td>[wellenförmige, muster, in, materiescheibe, um...</td>\n",
       "      <td>[wellenförmige, muster, materiescheibe, au, mi...</td>\n",
       "      <td>wellenförmige muster materiescheibe au microsc...</td>\n",
       "      <td>[wellenförmige, muster, materiescheibe, au, mi...</td>\n",
       "      <td>wellenförmige muster materiescheibe au microsc...</td>\n",
       "      <td>[wellenform, must, materiescheib, au, microsco...</td>\n",
       "      <td>wellenform must materiescheib au microscopii l...</td>\n",
       "      <td>[3, 11855, 12998, 9719, 50, 26391, 16348, 259,...</td>\n",
       "      <td>Wissenschaft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8946</th>\n",
       "      <td>Der NSA-Whistleblower war Thema bei der Debatt...</td>\n",
       "      <td>Web</td>\n",
       "      <td>[der, nsa-whistleblower, war, thema, bei, der,...</td>\n",
       "      <td>[nsa-whistleblower, thema, debatte, demokratis...</td>\n",
       "      <td>nsa-whistleblower thema debatte demokratischen...</td>\n",
       "      <td>[nsa-whistleblower, thema, debatte, demokratis...</td>\n",
       "      <td>nsa-whistleblower thema debatte demokratisch p...</td>\n",
       "      <td>[nsa-whistleblow, thema, debatt, demokrat, pra...</td>\n",
       "      <td>nsa-whistleblow thema debatt demokrat prasiden...</td>\n",
       "      <td>[3, 233, 25269, 26935, 6342, 324, 7446, 9931, ...</td>\n",
       "      <td>Web</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2344</th>\n",
       "      <td>Drei Debütanten aus Österreich nehmen die 102....</td>\n",
       "      <td>Sport</td>\n",
       "      <td>[drei, debütanten, aus, österreich, nehmen, di...</td>\n",
       "      <td>[drei, debütanten, österreich, nehmen, 102, .,...</td>\n",
       "      <td>drei debütanten österreich nehmen 102 . tour d...</td>\n",
       "      <td>[drei, debütanten, österreich, nehmen, 102, to...</td>\n",
       "      <td>drei debütanten österreich nehmen 102 tour de ...</td>\n",
       "      <td>[drei, debutant, osterreich, nehm, 102, tour, ...</td>\n",
       "      <td>drei debutant osterreich nehm 102 tour de fran...</td>\n",
       "      <td>[3, 2955, 7122, 2441, 147, 2661, 3513, 30, 202...</td>\n",
       "      <td>Sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>Drei Männer planten Anschläge. Bern – Wegen ve...</td>\n",
       "      <td>International</td>\n",
       "      <td>[drei, männer, planten, anschläge, ., bern, –,...</td>\n",
       "      <td>[drei, männer, planten, anschläge, ., bern, –,...</td>\n",
       "      <td>drei männer planten anschläge . bern – wegen v...</td>\n",
       "      <td>[drei, männer, planen, anschläge, bern, wegen,...</td>\n",
       "      <td>drei männer planen anschläge bern wegen versuc...</td>\n",
       "      <td>[drei, mann, plant, anschlag, bern, weg, versu...</td>\n",
       "      <td>drei mann plant anschlag bern weg versucht bei...</td>\n",
       "      <td>[3, 2955, 3284, 20708, 26898, 20276, 26914, 30...</td>\n",
       "      <td>International</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9024</th>\n",
       "      <td>Maskierter stach auf Schüler und Lehrer ein – ...</td>\n",
       "      <td>Panorama</td>\n",
       "      <td>[maskierter, stach, auf, schüler, und, lehrer,...</td>\n",
       "      <td>[maskierter, stach, schüler, lehrer, –, bub, l...</td>\n",
       "      <td>maskierter stach schüler lehrer – bub lehrer s...</td>\n",
       "      <td>[maskiert, stechen, schüler, lehrer, bub, lehr...</td>\n",
       "      <td>maskiert stechen schüler lehrer bub lehrer ste...</td>\n",
       "      <td>[maskiert, stach, schul, lehr, bub, lehr, star...</td>\n",
       "      <td>maskiert stach schul lehr bub lehr starb tat p...</td>\n",
       "      <td>[3, 8359, 4824, 11311, 26900, 19516, 8, 115, 3...</td>\n",
       "      <td>Panorama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4313</th>\n",
       "      <td>Bürgermeister erinnert an Bosnien-Krise – SPÖ ...</td>\n",
       "      <td>Panorama</td>\n",
       "      <td>[bürgermeister, erinnert, an, bosnien-krise, –...</td>\n",
       "      <td>[bürgermeister, erinnert, bosnien-krise, –, sp...</td>\n",
       "      <td>bürgermeister erinnert bosnien-krise – spö rin...</td>\n",
       "      <td>[bürgermeister, erinnern, bosnien-krise, spö, ...</td>\n",
       "      <td>bürgermeister erinnern bosnien-krise spö ringe...</td>\n",
       "      <td>[burgermeist, erinnert, bosnien-kris, spo, rin...</td>\n",
       "      <td>burgermeist erinnert bosnien-kris spo ringt ei...</td>\n",
       "      <td>[3, 3741, 6446, 104, 20913, 26935, 8130, 2, 26...</td>\n",
       "      <td>Panorama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          text_original          label  \\\n",
       "9073  1556 – Der Erzbischof von Canterbury, Thomas C...   Wissenschaft   \n",
       "8537  Gemma Bundesheer schauen! Nationalfeiertag auf...         Inland   \n",
       "4544  Am Montag wurde Insolvenz angemeldet. Georg Pf...     Wirtschaft   \n",
       "1547  Drei Fragen in zweifelhafter Nachrichtenumgebu...         Inland   \n",
       "1954  Wellenförmige Muster in Materiescheibe um AU M...   Wissenschaft   \n",
       "8946  Der NSA-Whistleblower war Thema bei der Debatt...            Web   \n",
       "2344  Drei Debütanten aus Österreich nehmen die 102....          Sport   \n",
       "1670  Drei Männer planten Anschläge. Bern – Wegen ve...  International   \n",
       "9024  Maskierter stach auf Schüler und Lehrer ein – ...       Panorama   \n",
       "4313  Bürgermeister erinnert an Bosnien-Krise – SPÖ ...       Panorama   \n",
       "\n",
       "                                         text_tokenized  \\\n",
       "9073  [1556, –, der, erzbischof, von, canterbury, ,,...   \n",
       "8537  [gemma, bundesheer, schauen, !, nationalfeiert...   \n",
       "4544  [am, montag, wurde, insolvenz, angemeldet, ., ...   \n",
       "1547  [drei, fragen, in, zweifelhafter, nachrichtenu...   \n",
       "1954  [wellenförmige, muster, in, materiescheibe, um...   \n",
       "8946  [der, nsa-whistleblower, war, thema, bei, der,...   \n",
       "2344  [drei, debütanten, aus, österreich, nehmen, di...   \n",
       "1670  [drei, männer, planten, anschläge, ., bern, –,...   \n",
       "9024  [maskierter, stach, auf, schüler, und, lehrer,...   \n",
       "4313  [bürgermeister, erinnert, an, bosnien-krise, –...   \n",
       "\n",
       "                                text_tokenized_keywords  \\\n",
       "9073  [1556, –, erzbischof, canterbury, ,, thomas, c...   \n",
       "8537  [gemma, bundesheer, schauen, !, nationalfeiert...   \n",
       "4544  [montag, wurde, insolvenz, angemeldet, ., geor...   \n",
       "1547  [drei, fragen, zweifelhafter, nachrichtenumgeb...   \n",
       "1954  [wellenförmige, muster, materiescheibe, au, mi...   \n",
       "8946  [nsa-whistleblower, thema, debatte, demokratis...   \n",
       "2344  [drei, debütanten, österreich, nehmen, 102, .,...   \n",
       "1670  [drei, männer, planten, anschläge, ., bern, –,...   \n",
       "9024  [maskierter, stach, schüler, lehrer, –, bub, l...   \n",
       "4313  [bürgermeister, erinnert, bosnien-krise, –, sp...   \n",
       "\n",
       "                                          text_keywords  \\\n",
       "9073  1556 – erzbischof canterbury , thomas cranmer ...   \n",
       "8537  gemma bundesheer schauen ! nationalfeiertag he...   \n",
       "4544  montag wurde insolvenz angemeldet . georg pfei...   \n",
       "1547  drei fragen zweifelhafter nachrichtenumgebung ...   \n",
       "1954  wellenförmige muster materiescheibe au microsc...   \n",
       "8946  nsa-whistleblower thema debatte demokratischen...   \n",
       "2344  drei debütanten österreich nehmen 102 . tour d...   \n",
       "1670  drei männer planten anschläge . bern – wegen v...   \n",
       "9024  maskierter stach schüler lehrer – bub lehrer s...   \n",
       "4313  bürgermeister erinnert bosnien-krise – spö rin...   \n",
       "\n",
       "                                  text_tokenized_lemmas  \\\n",
       "9073  [1556, erzbischof, canterbury, thomas, cranmer...   \n",
       "8537  [gemma, bundesheer, schauen, nationalfeiertag,...   \n",
       "4544  [montag, werden, insolvenz, anmelden, georg, p...   \n",
       "1547  [drei, fragen, zweifelhaft, nachrichtenumgebun...   \n",
       "1954  [wellenförmige, muster, materiescheibe, au, mi...   \n",
       "8946  [nsa-whistleblower, thema, debatte, demokratis...   \n",
       "2344  [drei, debütanten, österreich, nehmen, 102, to...   \n",
       "1670  [drei, männer, planen, anschläge, bern, wegen,...   \n",
       "9024  [maskiert, stechen, schüler, lehrer, bub, lehr...   \n",
       "4313  [bürgermeister, erinnern, bosnien-krise, spö, ...   \n",
       "\n",
       "                                            text_lemmas  \\\n",
       "9073  1556 erzbischof canterbury thomas cranmer oxfo...   \n",
       "8537  gemma bundesheer schauen nationalfeiertag held...   \n",
       "4544  montag werden insolvenz anmelden georg pfeiffe...   \n",
       "1547  drei fragen zweifelhaft nachrichtenumgebung fp...   \n",
       "1954  wellenförmige muster materiescheibe au microsc...   \n",
       "8946  nsa-whistleblower thema debatte demokratisch p...   \n",
       "2344  drei debütanten österreich nehmen 102 tour de ...   \n",
       "1670  drei männer planen anschläge bern wegen versuc...   \n",
       "9024  maskiert stechen schüler lehrer bub lehrer ste...   \n",
       "4313  bürgermeister erinnern bosnien-krise spö ringe...   \n",
       "\n",
       "                                 text_tokenized_stemmed  \\\n",
       "9073  [1556, erzbischof, canterbury, thomas, cranm, ...   \n",
       "8537  [gemma, bundeshe, schau, nationalfeiertag, hel...   \n",
       "4544  [montag, wurd, insolvenz, angemeldet, georg, p...   \n",
       "1547  [drei, frag, zweifelhaft, nachrichtenumgeb, fp...   \n",
       "1954  [wellenform, must, materiescheib, au, microsco...   \n",
       "8946  [nsa-whistleblow, thema, debatt, demokrat, pra...   \n",
       "2344  [drei, debutant, osterreich, nehm, 102, tour, ...   \n",
       "1670  [drei, mann, plant, anschlag, bern, weg, versu...   \n",
       "9024  [maskiert, stach, schul, lehr, bub, lehr, star...   \n",
       "4313  [burgermeist, erinnert, bosnien-kris, spo, rin...   \n",
       "\n",
       "                                              text_stem  \\\n",
       "9073  1556 erzbischof canterbury thomas cranm oxford...   \n",
       "8537  gemma bundeshe schau nationalfeiertag heldenpl...   \n",
       "4544  montag wurd insolvenz angemeldet georg pfeiff ...   \n",
       "1547  drei frag zweifelhaft nachrichtenumgeb fpo-kan...   \n",
       "1954  wellenform must materiescheib au microscopii l...   \n",
       "8946  nsa-whistleblow thema debatt demokrat prasiden...   \n",
       "2344  drei debutant osterreich nehm 102 tour de fran...   \n",
       "1670  drei mann plant anschlag bern weg versucht bei...   \n",
       "9024  maskiert stach schul lehr bub lehr starb tat p...   \n",
       "4313  burgermeist erinnert bosnien-kris spo ringt ei...   \n",
       "\n",
       "                                           hf_tokenized     prediction  \n",
       "9073  [3, 19041, 26960, 2, 233, 9443, 88, 21447, 756...  International  \n",
       "8537  [3, 610, 751, 578, 14986, 17036, 26982, 1921, ...       Panorama  \n",
       "4544  [3, 570, 4141, 192, 4461, 20095, 26914, 3578, ...     Wirtschaft  \n",
       "1547  [3, 2955, 4168, 50, 21618, 6, 4663, 107, 4209,...           Etat  \n",
       "1954  [3, 11855, 12998, 9719, 50, 26391, 16348, 259,...   Wissenschaft  \n",
       "8946  [3, 233, 25269, 26935, 6342, 324, 7446, 9931, ...            Web  \n",
       "2344  [3, 2955, 7122, 2441, 147, 2661, 3513, 30, 202...          Sport  \n",
       "1670  [3, 2955, 3284, 20708, 26898, 20276, 26914, 30...  International  \n",
       "9024  [3, 8359, 4824, 11311, 26900, 19516, 8, 115, 3...       Panorama  \n",
       "4313  [3, 3741, 6446, 104, 20913, 26935, 8130, 2, 26...       Panorama  "
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = Series(y_predict).rename(\"prediction\").to_frame().set_index(sample.index)\n",
    "concat([sample, prediction], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a48032-c136-482f-928c-4dfaa3f51f00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m84",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m84"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
