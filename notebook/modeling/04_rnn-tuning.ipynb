{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59ef7e85-7d2f-4c14-a0a1-6e075637b7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-14 22:25:59.562887: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-14 22:25:59.590508: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-14 22:25:59.591131: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "import tensorflow as tf\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44035168-1ecd-4f35-b5ef-426da80cabd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./logs/hparam_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f86ade6-2106-484e-9434-6dff980e4584",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_parquet\n",
    "from data import file\n",
    "\n",
    "data_train = read_parquet(file.news_articles_cleaned_train)\n",
    "data_test = read_parquet(file.news_articles_cleaned_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea5d6e5c-c066-4fb5-9f0b-50febf23e2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-14 22:26:02.441316: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-14 22:26:02.442257: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-14 22:26:02.442917: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-14 22:26:02.443472: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-14 22:26:02.930635: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-14 22:26:02.931369: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-14 22:26:02.931950: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-14 22:26:02.932516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13839 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None,), (None, 9)), types: (tf.string, tf.int64)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from preprocessing.categorical import binarizer\n",
    "\n",
    "\n",
    "X_train = data_train.text_tokenized_stemmed\n",
    "y_train = data_train.label\n",
    "\n",
    "X_test = data_test.text_tokenized_stemmed\n",
    "y_test = data_test.label\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "y_train = data_train.label\n",
    "label_binarizer=binarizer(y_train)\n",
    "\n",
    "\n",
    "x_train = data_train['text_stem']\n",
    "y_train_bin = label_binarizer.transform(y_train)\n",
    "\n",
    "x_test = data_test['text_stem']\n",
    "y_test_bin = label_binarizer.transform(y_test)\n",
    "\n",
    "train_input = tf.data.Dataset.from_tensor_slices((x_train, y_train_bin)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "test_input = tf.data.Dataset.from_tensor_slices((x_test, y_test_bin)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "train_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61d125b0-c028-4590-9cbe-b4db949d4ae6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b85a447c454891ef\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b85a447c454891ef\");\n",
       "          const url = new URL(\"/proxy/6006/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/hparam_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e33febf-9393-414a-b505-001baab249c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-0\n",
      "{'num_layers': 1, 'num_rnn_units': 32}\n",
      "Median sequence length:       : 173\n",
      "Percentil                     : 0.98)\n",
      "Cutoff sequence length        : 589\n",
      "Max sequence length           : 1699\n",
      "Embedding length              : 589\n",
      "Vocabulary length             : 162207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"rnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text_vectorization (TextVect (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 300)         48662100  \n",
      "_________________________________________________________________\n",
      "bidirectional_lstm_0 (Bidire (None, None, 64)          85248     \n",
      "_________________________________________________________________\n",
      "global_max_pool (GlobalMaxPo (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "prediction (Dense)           (None, 9)                 585       \n",
      "=================================================================\n",
      "Total params: 48,747,933\n",
      "Trainable params: 85,833\n",
      "Non-trainable params: 48,662,100\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-14 22:26:38.286854: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-11-14 22:26:38.286905: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2021-11-14 22:26:38.289792: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1614] Profiler found 1 GPUs\n",
      "2021-11-14 22:26:38.495016: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2021-11-14 22:26:38.495205: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1748] CUPTI activity buffer flushed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-14 22:26:45.549083: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-14 22:26:47.262710: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/289 [..............................] - ETA: 49:09 - loss: 2.2297 - accuracy: 0.0625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-14 22:26:50.227369: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-11-14 22:26:50.227412: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/289 [..............................] - ETA: 4:29 - loss: 2.2232 - accuracy: 0.0625 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-14 22:26:50.998958: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2021-11-14 22:26:51.007855: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1748] CUPTI activity buffer flushed\n",
      "2021-11-14 22:26:51.138850: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 13265 callback api events and 13262 activity events. \n",
      "2021-11-14 22:26:51.367738: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2021-11-14 22:26:51.749494: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/hparam_tuning/train/plugins/profile/2021_11_14_22_26_51\n",
      "\n",
      "2021-11-14 22:26:51.946585: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to logs/hparam_tuning/train/plugins/profile/2021_11_14_22_26_51/frankfurt-tf-26-cpu-2-gpu-1.trace.json.gz\n",
      "2021-11-14 22:26:52.120288: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/hparam_tuning/train/plugins/profile/2021_11_14_22_26_51\n",
      "\n",
      "2021-11-14 22:26:52.123888: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to logs/hparam_tuning/train/plugins/profile/2021_11_14_22_26_51/frankfurt-tf-26-cpu-2-gpu-1.memory_profile.json.gz\n",
      "2021-11-14 22:26:52.126543: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/hparam_tuning/train/plugins/profile/2021_11_14_22_26_51\n",
      "Dumped tool data for xplane.pb to logs/hparam_tuning/train/plugins/profile/2021_11_14_22_26_51/frankfurt-tf-26-cpu-2-gpu-1.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs/hparam_tuning/train/plugins/profile/2021_11_14_22_26_51/frankfurt-tf-26-cpu-2-gpu-1.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/hparam_tuning/train/plugins/profile/2021_11_14_22_26_51/frankfurt-tf-26-cpu-2-gpu-1.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/hparam_tuning/train/plugins/profile/2021_11_14_22_26_51/frankfurt-tf-26-cpu-2-gpu-1.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/hparam_tuning/train/plugins/profile/2021_11_14_22_26_51/frankfurt-tf-26-cpu-2-gpu-1.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/289 [==============================] - 79s 240ms/step - loss: 1.6923 - accuracy: 0.3951 - val_loss: 1.4940 - val_accuracy: 0.4825\n",
      "Epoch 2/5\n",
      "289/289 [==============================] - 64s 223ms/step - loss: 1.2807 - accuracy: 0.5586 - val_loss: 1.3535 - val_accuracy: 0.5370\n",
      "Epoch 3/5\n",
      "289/289 [==============================] - 64s 223ms/step - loss: 1.0696 - accuracy: 0.6353 - val_loss: 1.2745 - val_accuracy: 0.5768\n",
      "Epoch 4/5\n",
      "289/289 [==============================] - 66s 227ms/step - loss: 0.8594 - accuracy: 0.7161 - val_loss: 1.1327 - val_accuracy: 0.6342\n",
      "Epoch 4/5\n",
      "289/289 [==============================] - 66s 227ms/step - loss: 0.6873 - accuracy: 0.7711 - val_loss: 1.1483 - val_accuracy: 0.6401\n",
      "Epoch 5/5\n",
      "289/289 [==============================] - 65s 226ms/step - loss: 0.5384 - accuracy: 0.8220 - val_loss: 1.3447 - val_accuracy: 0.6294\n",
      "33/33 [==============================] - 7s 204ms/step - loss: 1.3447 - accuracy: 0.6294\n"
     ]
    }
   ],
   "source": [
    "from keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from preprocessing.categorical import binarizer\n",
    "from models import rnn\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "\n",
    "logdir='logs/hparam_tuning/'\n",
    "session_num = 0\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "HP_NUM_LAYERS = hp.HParam('num_layers', hp.Discrete([1]))\n",
    "HP_NUM_RNN_UNITS = hp.HParam('num_rnn_units', hp.Discrete([32, 64, 96]))\n",
    "\n",
    "\n",
    "def train_test_model(hparams):\n",
    "    \n",
    "    learning_rate=0.02\n",
    "    model_metric = [\"accuracy\"]\n",
    "    loss_function = CategoricalCrossentropy()\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    output_classes = len(label_binarizer.classes_)\n",
    "    rnn_layers = hparams[HP_NUM_LAYERS]\n",
    "    rnn_units = hparams[HP_NUM_RNN_UNITS]\n",
    "    \n",
    "    \n",
    "    model, model_name = rnn.build_model(X_train, y_train, output_classes, rnn_num_layers = rnn_layers, rnn_units=rnn_units)\n",
    "    model.summary()\n",
    "    model.compile(loss=loss_function, optimizer=optimizer, metrics=model_metric)\n",
    "    \n",
    "    history = model.fit(train_input, validation_data=test_input, epochs=5, callbacks=[\n",
    "        tf.keras.callbacks.TensorBoard(logdir),\n",
    "        hp.KerasCallback(logdir, hparams),\n",
    "    ])\n",
    "    _, accuracy = model.evaluate(x_test, y_test_bin)\n",
    "    return accuracy\n",
    "\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "  hp.hparams_config(\n",
    "    hparams=[HP_NUM_LAYERS],\n",
    "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
    "  )\n",
    "\n",
    "\n",
    "def run(run_dir, hparams):\n",
    "  with tf.summary.create_file_writer(run_dir).as_default():\n",
    "    hp.hparams(hparams)\n",
    "    accuracy = train_test_model(hparams)\n",
    "    tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)\n",
    "\n",
    "\n",
    "\n",
    "for num_layers in HP_NUM_LAYERS.domain.values:\n",
    "    for num_rnn_units in HP_NUM_RNN_UNITS.domain.values:\n",
    "        hparams = {\n",
    "            HP_NUM_LAYERS: num_layers,\n",
    "            HP_NUM_RNN_UNITS: num_rnn_units,\n",
    "        }\n",
    "        \n",
    "        run_name = \"run-%d\" % session_num\n",
    "        print('--- Starting trial: %s' % run_name)\n",
    "        print({h.name: hparams[h] for h in hparams})\n",
    "        run(f\"{logdir}{run_name}\", hparams)\n",
    "        session_num += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e603aad-4af8-405f-b894-b183e62c2981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805709c2-022a-47f2-a758-32b341a5cadd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m82",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m82"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
