{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_parquet\n",
    "from data import file\n",
    "\n",
    "data_train = read_parquet(file.news_articles_cleaned_train)\n",
    "data_test = read_parquet(file.news_articles_cleaned_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_original</th>\n",
       "      <th>label</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>text_tokenized_keywords</th>\n",
       "      <th>text_keywords</th>\n",
       "      <th>text_tokenized_lemmas</th>\n",
       "      <th>text_lemmas</th>\n",
       "      <th>text_tokenized_stemmed</th>\n",
       "      <th>text_stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21-Jähriger fällt wohl bis Saisonende aus. Wie...</td>\n",
       "      <td>Sport</td>\n",
       "      <td>[21-jähriger, fällt, wohl, bis, saisonende, au...</td>\n",
       "      <td>[21-jähriger, fällt, wohl, saisonende, ., wien...</td>\n",
       "      <td>21-jähriger fällt wohl saisonende . wien – rap...</td>\n",
       "      <td>[21-jähriger, fällen, wohl, saisonende, wien, ...</td>\n",
       "      <td>21-jähriger fällen wohl saisonende wien rapid ...</td>\n",
       "      <td>[21-jahrig, fallt, wohl, saison, wien, rapid, ...</td>\n",
       "      <td>21-jahrig fallt wohl saison wien rapid wohl sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Erfundene Bilder zu Filmen, die als verloren g...</td>\n",
       "      <td>Kultur</td>\n",
       "      <td>[erfundene, bilder, zu, filmen, ,, die, als, v...</td>\n",
       "      <td>[erfundene, bilder, filmen, ,, verloren, gelte...</td>\n",
       "      <td>erfundene bilder filmen , verloren gelten : ``...</td>\n",
       "      <td>[erfunden, bilder, filmen, verlieren, gelten, ...</td>\n",
       "      <td>erfunden bilder filmen verlieren gelten `` the...</td>\n",
       "      <td>[erfund, bild, film, verlor, gelt, ``, the, fo...</td>\n",
       "      <td>erfund bild film verlor gelt `` the forbidd ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Der frischgekürte CEO Sundar Pichai setzt auf ...</td>\n",
       "      <td>Web</td>\n",
       "      <td>[der, frischgekürte, ceo, sundar, pichai, setz...</td>\n",
       "      <td>[frischgekürte, ceo, sundar, pichai, setzt, um...</td>\n",
       "      <td>frischgekürte ceo sundar pichai setzt umgängli...</td>\n",
       "      <td>[frischgekürte, ceo, sundar, pichai, setzen, u...</td>\n",
       "      <td>frischgekürte ceo sundar pichai setzen umgängl...</td>\n",
       "      <td>[frischgekurt, ceo, sundar, pichai, setzt, umg...</td>\n",
       "      <td>frischgekurt ceo sundar pichai setzt umgang fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Putin: \"Einigung, dass wir Menge auf Niveau vo...</td>\n",
       "      <td>Wirtschaft</td>\n",
       "      <td>[putin, :, ``, einigung, ,, dass, wir, menge, ...</td>\n",
       "      <td>[putin, :, ``, einigung, ,, menge, niveau, jän...</td>\n",
       "      <td>putin : `` einigung , menge niveau jänner halt...</td>\n",
       "      <td>[putin, ``, einigung, menge, niveau, jänner, h...</td>\n",
       "      <td>putin `` einigung menge niveau jänner halten m...</td>\n",
       "      <td>[putin, ``, einig, meng, niveau, jann, halt, '...</td>\n",
       "      <td>putin `` einig meng niveau jann halt '' moskau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Estland sieht den künftigen österreichischen P...</td>\n",
       "      <td>Inland</td>\n",
       "      <td>[estland, sieht, den, künftigen, österreichisc...</td>\n",
       "      <td>[estland, sieht, künftigen, österreichischen, ...</td>\n",
       "      <td>estland sieht künftigen österreichischen präsi...</td>\n",
       "      <td>[estland, sehen, künftig, österreichisch, präs...</td>\n",
       "      <td>estland sehen künftig österreichisch präsident...</td>\n",
       "      <td>[estland, sieht, kunftig, osterreich, prasiden...</td>\n",
       "      <td>estland sieht kunftig osterreich prasident est...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9240</th>\n",
       "      <td>Bernd Saurer war Bridge-Juniorenweltmeister un...</td>\n",
       "      <td>Inland</td>\n",
       "      <td>[bernd, saurer, war, bridge-juniorenweltmeiste...</td>\n",
       "      <td>[bernd, saurer, bridge-juniorenweltmeister, ,,...</td>\n",
       "      <td>bernd saurer bridge-juniorenweltmeister , krau...</td>\n",
       "      <td>[bernd, sauer, bridge-juniorenweltmeister, kra...</td>\n",
       "      <td>bernd sauer bridge-juniorenweltmeister krauss ...</td>\n",
       "      <td>[bernd, saur, bridge-juniorenweltmeist, krauss...</td>\n",
       "      <td>bernd saur bridge-juniorenweltmeist krauss sch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9241</th>\n",
       "      <td>Sandhere soll in vergangener Woche bei Luftang...</td>\n",
       "      <td>International</td>\n",
       "      <td>[sandhere, soll, in, vergangener, woche, bei, ...</td>\n",
       "      <td>[sandhere, vergangener, woche, luftangriff, ge...</td>\n",
       "      <td>sandhere vergangener woche luftangriff getötet...</td>\n",
       "      <td>[sandhere, vergangen, woche, luftangriff, töte...</td>\n",
       "      <td>sandhere vergangen woche luftangriff töten wer...</td>\n",
       "      <td>[sandh, vergang, woch, luftangriff, getotet, w...</td>\n",
       "      <td>sandh vergang woch luftangriff getotet word wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9242</th>\n",
       "      <td>Derzeit Konzeptgruppe in Berlin – Kein Komment...</td>\n",
       "      <td>Wirtschaft</td>\n",
       "      <td>[derzeit, konzeptgruppe, in, berlin, –, kein, ...</td>\n",
       "      <td>[derzeit, konzeptgruppe, berlin, –, kommentar,...</td>\n",
       "      <td>derzeit konzeptgruppe berlin – kommentar apple...</td>\n",
       "      <td>[derzeit, konzeptgruppe, berlin, kommentar, ap...</td>\n",
       "      <td>derzeit konzeptgruppe berlin kommentar apple m...</td>\n",
       "      <td>[derzeit, konzeptgrupp, berlin, kommentar, app...</td>\n",
       "      <td>derzeit konzeptgrupp berlin kommentar appl mag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9243</th>\n",
       "      <td>Landeshauptmann will den vierten Regierungssit...</td>\n",
       "      <td>Inland</td>\n",
       "      <td>[landeshauptmann, will, den, vierten, regierun...</td>\n",
       "      <td>[landeshauptmann, vierten, regierungssitz, erh...</td>\n",
       "      <td>landeshauptmann vierten regierungssitz erhalte...</td>\n",
       "      <td>[landeshauptmann, viert, regierungssitz, erhal...</td>\n",
       "      <td>landeshauptmann viert regierungssitz erhalten ...</td>\n",
       "      <td>[landeshauptmann, viert, regierungssitz, erhal...</td>\n",
       "      <td>landeshauptmann viert regierungssitz erhalt fp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9244</th>\n",
       "      <td>Er ist einer von Millionen syrischen Flüchtlin...</td>\n",
       "      <td>Panorama</td>\n",
       "      <td>[er, ist, einer, von, millionen, syrischen, fl...</td>\n",
       "      <td>[millionen, syrischen, flüchtlingen, ., kamera...</td>\n",
       "      <td>millionen syrischen flüchtlingen . kamerafrau ...</td>\n",
       "      <td>[millionen, syrisch, flüchtlingen, kamerafrau,...</td>\n",
       "      <td>millionen syrisch flüchtlingen kamerafrau rech...</td>\n",
       "      <td>[million, syrisch, fluchtling, kamerafrau, rec...</td>\n",
       "      <td>million syrisch fluchtling kamerafrau rechtsge...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9245 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          text_original          label  \\\n",
       "0     21-Jähriger fällt wohl bis Saisonende aus. Wie...          Sport   \n",
       "1     Erfundene Bilder zu Filmen, die als verloren g...         Kultur   \n",
       "2     Der frischgekürte CEO Sundar Pichai setzt auf ...            Web   \n",
       "3     Putin: \"Einigung, dass wir Menge auf Niveau vo...     Wirtschaft   \n",
       "4     Estland sieht den künftigen österreichischen P...         Inland   \n",
       "...                                                 ...            ...   \n",
       "9240  Bernd Saurer war Bridge-Juniorenweltmeister un...         Inland   \n",
       "9241  Sandhere soll in vergangener Woche bei Luftang...  International   \n",
       "9242  Derzeit Konzeptgruppe in Berlin – Kein Komment...     Wirtschaft   \n",
       "9243  Landeshauptmann will den vierten Regierungssit...         Inland   \n",
       "9244  Er ist einer von Millionen syrischen Flüchtlin...       Panorama   \n",
       "\n",
       "                                         text_tokenized  \\\n",
       "0     [21-jähriger, fällt, wohl, bis, saisonende, au...   \n",
       "1     [erfundene, bilder, zu, filmen, ,, die, als, v...   \n",
       "2     [der, frischgekürte, ceo, sundar, pichai, setz...   \n",
       "3     [putin, :, ``, einigung, ,, dass, wir, menge, ...   \n",
       "4     [estland, sieht, den, künftigen, österreichisc...   \n",
       "...                                                 ...   \n",
       "9240  [bernd, saurer, war, bridge-juniorenweltmeiste...   \n",
       "9241  [sandhere, soll, in, vergangener, woche, bei, ...   \n",
       "9242  [derzeit, konzeptgruppe, in, berlin, –, kein, ...   \n",
       "9243  [landeshauptmann, will, den, vierten, regierun...   \n",
       "9244  [er, ist, einer, von, millionen, syrischen, fl...   \n",
       "\n",
       "                                text_tokenized_keywords  \\\n",
       "0     [21-jähriger, fällt, wohl, saisonende, ., wien...   \n",
       "1     [erfundene, bilder, filmen, ,, verloren, gelte...   \n",
       "2     [frischgekürte, ceo, sundar, pichai, setzt, um...   \n",
       "3     [putin, :, ``, einigung, ,, menge, niveau, jän...   \n",
       "4     [estland, sieht, künftigen, österreichischen, ...   \n",
       "...                                                 ...   \n",
       "9240  [bernd, saurer, bridge-juniorenweltmeister, ,,...   \n",
       "9241  [sandhere, vergangener, woche, luftangriff, ge...   \n",
       "9242  [derzeit, konzeptgruppe, berlin, –, kommentar,...   \n",
       "9243  [landeshauptmann, vierten, regierungssitz, erh...   \n",
       "9244  [millionen, syrischen, flüchtlingen, ., kamera...   \n",
       "\n",
       "                                          text_keywords  \\\n",
       "0     21-jähriger fällt wohl saisonende . wien – rap...   \n",
       "1     erfundene bilder filmen , verloren gelten : ``...   \n",
       "2     frischgekürte ceo sundar pichai setzt umgängli...   \n",
       "3     putin : `` einigung , menge niveau jänner halt...   \n",
       "4     estland sieht künftigen österreichischen präsi...   \n",
       "...                                                 ...   \n",
       "9240  bernd saurer bridge-juniorenweltmeister , krau...   \n",
       "9241  sandhere vergangener woche luftangriff getötet...   \n",
       "9242  derzeit konzeptgruppe berlin – kommentar apple...   \n",
       "9243  landeshauptmann vierten regierungssitz erhalte...   \n",
       "9244  millionen syrischen flüchtlingen . kamerafrau ...   \n",
       "\n",
       "                                  text_tokenized_lemmas  \\\n",
       "0     [21-jähriger, fällen, wohl, saisonende, wien, ...   \n",
       "1     [erfunden, bilder, filmen, verlieren, gelten, ...   \n",
       "2     [frischgekürte, ceo, sundar, pichai, setzen, u...   \n",
       "3     [putin, ``, einigung, menge, niveau, jänner, h...   \n",
       "4     [estland, sehen, künftig, österreichisch, präs...   \n",
       "...                                                 ...   \n",
       "9240  [bernd, sauer, bridge-juniorenweltmeister, kra...   \n",
       "9241  [sandhere, vergangen, woche, luftangriff, töte...   \n",
       "9242  [derzeit, konzeptgruppe, berlin, kommentar, ap...   \n",
       "9243  [landeshauptmann, viert, regierungssitz, erhal...   \n",
       "9244  [millionen, syrisch, flüchtlingen, kamerafrau,...   \n",
       "\n",
       "                                            text_lemmas  \\\n",
       "0     21-jähriger fällen wohl saisonende wien rapid ...   \n",
       "1     erfunden bilder filmen verlieren gelten `` the...   \n",
       "2     frischgekürte ceo sundar pichai setzen umgängl...   \n",
       "3     putin `` einigung menge niveau jänner halten m...   \n",
       "4     estland sehen künftig österreichisch präsident...   \n",
       "...                                                 ...   \n",
       "9240  bernd sauer bridge-juniorenweltmeister krauss ...   \n",
       "9241  sandhere vergangen woche luftangriff töten wer...   \n",
       "9242  derzeit konzeptgruppe berlin kommentar apple m...   \n",
       "9243  landeshauptmann viert regierungssitz erhalten ...   \n",
       "9244  millionen syrisch flüchtlingen kamerafrau rech...   \n",
       "\n",
       "                                 text_tokenized_stemmed  \\\n",
       "0     [21-jahrig, fallt, wohl, saison, wien, rapid, ...   \n",
       "1     [erfund, bild, film, verlor, gelt, ``, the, fo...   \n",
       "2     [frischgekurt, ceo, sundar, pichai, setzt, umg...   \n",
       "3     [putin, ``, einig, meng, niveau, jann, halt, '...   \n",
       "4     [estland, sieht, kunftig, osterreich, prasiden...   \n",
       "...                                                 ...   \n",
       "9240  [bernd, saur, bridge-juniorenweltmeist, krauss...   \n",
       "9241  [sandh, vergang, woch, luftangriff, getotet, w...   \n",
       "9242  [derzeit, konzeptgrupp, berlin, kommentar, app...   \n",
       "9243  [landeshauptmann, viert, regierungssitz, erhal...   \n",
       "9244  [million, syrisch, fluchtling, kamerafrau, rec...   \n",
       "\n",
       "                                              text_stem  \n",
       "0     21-jahrig fallt wohl saison wien rapid wohl sa...  \n",
       "1     erfund bild film verlor gelt `` the forbidd ro...  \n",
       "2     frischgekurt ceo sundar pichai setzt umgang fu...  \n",
       "3     putin `` einig meng niveau jann halt '' moskau...  \n",
       "4     estland sieht kunftig osterreich prasident est...  \n",
       "...                                                 ...  \n",
       "9240  bernd saur bridge-juniorenweltmeist krauss sch...  \n",
       "9241  sandh vergang woch luftangriff getotet word wa...  \n",
       "9242  derzeit konzeptgrupp berlin kommentar appl mag...  \n",
       "9243  landeshauptmann viert regierungssitz erhalt fp...  \n",
       "9244  million syrisch fluchtling kamerafrau rechtsge...  \n",
       "\n",
       "[9245 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import TextVectorization\n",
    "import fasttext.util\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Conv1D, GlobalMaxPooling1D, InputLayer\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras import Sequential\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "def get_embedder_fasttext(embedding_dim, model_name=\"cc.de.300.bin\"):\n",
    "    split = model_name.split(\".\")\n",
    "    model_lang = split[1]\n",
    "    model_dim = int(split[2])\n",
    "\n",
    "    try:\n",
    "        ft = fasttext.load_model(model_name)\n",
    "    except ValueError:\n",
    "        fasttext.util.download_model(model_lang, if_exists='ignore')\n",
    "        ft = fasttext.load_model(model_name)\n",
    "\n",
    "    if embedding_dim < model_dim:\n",
    "        fasttext.util.reduce_model(ft, embedding_dim)\n",
    "\n",
    "    def fasttext_embedder(word):\n",
    "        return ft.get_word_vector(word)\n",
    "\n",
    "    return fasttext_embedder\n",
    "\n",
    "\n",
    "def calculate_embedding_matrix(vocabulary, embedding_dim=300, verbose=False):\n",
    "    \"\"\"Creates the embedding matrix\n",
    "    \"\"\"\n",
    "    voc_size = len(vocabulary)\n",
    "    words_not_found = set()\n",
    "    embedding_matrix = np.zeros((voc_size, embedding_dim))\n",
    "\n",
    "    embedder = get_embedder_fasttext(embedding_dim)\n",
    "    \n",
    "    \n",
    "    for idx, word in enumerate(vocabulary):\n",
    "        embedding_vector = embedder(word)\n",
    "        if (embedding_vector is not None) and len(embedding_vector) > 0 and not np.all(embedding_vector == 0):\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[idx] = embedding_vector\n",
    "        else:\n",
    "            words_not_found.add(word)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Embedding type: fasttext\")\n",
    "        print(\"Number of null word embeddings:\", np.sum(np.sum(embedding_matrix, axis=1) == 0))\n",
    "        nr_words_not_found = len(words_not_found)\n",
    "        print(\"Words not found in total:\", len(words_not_found))\n",
    "        if nr_words_not_found > 0:\n",
    "            import random\n",
    "\n",
    "            nr_sample = min(20, len(words_not_found))\n",
    "            print(\"Words without embedding (\", nr_sample, \"/\", nr_words_not_found, \"): \",\n",
    "                  random.sample(words_not_found, nr_sample), sep='')\n",
    "\n",
    "    return embedding_matrix\n",
    "\n",
    "\n",
    "def extract_vocabulary_and_set(data, verbose=False):\n",
    "    sequence_length_percentil_cutoff = 0.98\n",
    "    sequence_length_max = 768\n",
    "\n",
    "    vocabulary = set()\n",
    "    _ = data.apply(lambda x: vocabulary.update(x))\n",
    "\n",
    "    lengths = data.apply(len)\n",
    "    max_sequence_length = int(lengths.quantile(1.0))\n",
    "    percentil_sequence_length = int(lengths.quantile(0.98))\n",
    "    median_sequence_length = int(lengths.quantile(0.5))\n",
    "    embedding_sequence_length = min(sequence_length_max, percentil_sequence_length)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Median sequence length:       : {median_sequence_length}\")\n",
    "        print(f\"Percentil                     : {sequence_length_percentil_cutoff})\")\n",
    "        print(f\"Cutoff sequence length        : {percentil_sequence_length}\")\n",
    "        print(f\"Max sequence length           : {max_sequence_length}\")\n",
    "        print(f\"Used embedding sequence length: {embedding_sequence_length}\")\n",
    "        print(f\"Vocabulary length             : {len(vocabulary)}\")\n",
    "\n",
    "    return (vocabulary, embedding_sequence_length)\n",
    "\n",
    "\n",
    "def compile_model(model, loss_function=\"categorical_crossentropy\", learning_rate=0.01, model_metric = [\"accuracy\"]):\n",
    "    adam = Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss=loss_function, optimizer=adam, metrics=model_metric)\n",
    "    \n",
    "    \n",
    "def build_model_cnn_simple(X_train, y_train, conv_num_filters=128, conv_kernel_size=7):\n",
    "\n",
    "    vocabulary, embedding_length = extract_vocabulary_and_set(X_train, verbose=True)\n",
    "    print(f\"embedding length: {embedding_length}\")\n",
    "    \n",
    "    embedding_matrix = calculate_embedding_matrix(vocabulary)\n",
    "    embedding_input_dim, embedding_output_dim = embedding_matrix.shape[0], embedding_matrix.shape[1]\n",
    "    \n",
    "    output_classes = len(y_train.unique())\n",
    "\n",
    "    vectorize_layer = TextVectorization(\n",
    "        output_mode='int',\n",
    "        output_sequence_length=None,\n",
    "        vocabulary=list(vocabulary),\n",
    "        name=\"text_vectorization\"\n",
    "    )\n",
    "\n",
    "    embedding_layer = Embedding(\n",
    "        embedding_input_dim,\n",
    "        embedding_output_dim,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=embedding_length,\n",
    "        trainable=False,\n",
    "        mask_zero=True,\n",
    "        name=\"embedding\"\n",
    "    )\n",
    "\n",
    "\n",
    "    model = Sequential(name=\"cnn\")\n",
    "    model.add(InputLayer(input_shape=(1,), dtype=tf.string, name=\"text_input\"))\n",
    "    model.add(vectorize_layer)\n",
    "    model.add(embedding_layer)\n",
    "    model.add(Conv1D(conv_num_filters, conv_kernel_size, activation=\"relu\", strides=1, padding=\"valid\", name=\"conv_1\"))\n",
    "    model.add(GlobalMaxPooling1D(name=\"global_max_pool_1\"))\n",
    "    model.add(Dense(output_classes, activation=tf.nn.softmax, name=\"prediction\"))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train.text_tokenized_stemmed\n",
    "y_train = data_train.label\n",
    "\n",
    "X_test = data_test.text_tokenized_stemmed\n",
    "y_test = data_test.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median sequence length:       : 173\n",
      "Percentil                     : 0.98)\n",
      "Cutoff sequence length        : 589\n",
      "Max sequence length           : 1699\n",
      "Used embedding sequence length: 589\n",
      "Vocabulary length             : 162207\n",
      "embedding length: 589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "2021-11-01 22:47:11.180686: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-01 22:47:11.257146: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-01 22:47:11.257793: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-01 22:47:11.260241: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-01 22:47:11.260693: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-01 22:47:11.261478: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-01 22:47:11.262051: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-01 22:47:13.371070: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-01 22:47:13.371864: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-01 22:47:13.372484: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-01 22:47:13.373841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13839 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text_vectorization (TextVect (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 300)         48662100  \n",
      "_________________________________________________________________\n",
      "conv_1 (Conv1D)              (None, None, 128)         268928    \n",
      "_________________________________________________________________\n",
      "global_max_pool_1 (GlobalMax (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "prediction (Dense)           (None, 9)                 1161      \n",
      "=================================================================\n",
      "Total params: 48,932,189\n",
      "Trainable params: 270,089\n",
      "Non-trainable params: 48,662,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model_cnn_simple(X_train, y_train)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "compile_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "y_train = data_train.label\n",
    "label_binarizer = LabelBinarizer()\n",
    "label_binarizer.fit(y_train)\n",
    "\n",
    "x_train = data_train['text_stem']\n",
    "y_train_bin = label_binarizer.transform(y_train)\n",
    "\n",
    "x_test = data_test['text_stem']\n",
    "y_test_bin = label_binarizer.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None,), (None, 9)), types: (tf.string, tf.int64)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "train_input = tf.data.Dataset.from_tensor_slices((x_train, y_train_bin)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "test_input = tf.data.Dataset.from_tensor_slices((x_test, y_test_bin)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "train_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 13695), started 0:07:47 ago. (Use '!kill 13695' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-fdbb9c677ade63aa\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-fdbb9c677ade63aa\");\n",
       "          const url = new URL(\"/proxy/6006/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "289/289 [==============================] - 52s 181ms/step - loss: 0.5264 - accuracy: 0.8312 - val_loss: 1.7993 - val_accuracy: 0.5525\n",
      "Epoch 2/5\n",
      "289/289 [==============================] - 52s 180ms/step - loss: 0.4275 - accuracy: 0.8598 - val_loss: 2.1472 - val_accuracy: 0.5311\n",
      "Epoch 3/5\n",
      "289/289 [==============================] - 52s 180ms/step - loss: 0.3090 - accuracy: 0.8983 - val_loss: 2.1774 - val_accuracy: 0.5632\n",
      "Epoch 4/5\n",
      "289/289 [==============================] - 52s 179ms/step - loss: 0.2182 - accuracy: 0.9292 - val_loss: 2.4447 - val_accuracy: 0.5584\n",
      "Epoch 5/5\n",
      "289/289 [==============================] - 52s 179ms/step - loss: 0.1697 - accuracy: 0.9453 - val_loss: 2.5847 - val_accuracy: 0.5525\n"
     ]
    }
   ],
   "source": [
    "#%tensorboard --logdir logs/fit\n",
    "\n",
    "#callbacks = [TensorBoard(\"logs/fit\", histogram_freq=1)]\n",
    "callbacks = []\n",
    "history = model.fit(train_input, validation_data=test_input, callbacks=callbacks, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sport', 'Kultur', 'Web', 'Wirtschaft', 'Inland', 'Wirtschaft',\n",
       "       'Sport', 'Etat', 'International', 'Sport'], dtype='<U13')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(x_train[0:10])\n",
    "label_binarizer.inverse_transform(prediction)\n",
    "\n",
    "y_train[]"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m82",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m82"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
