{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_parquet\n",
    "from data import file\n",
    "\n",
    "data_train = read_parquet(file.news_articles_cleaned_train)\n",
    "data_test = read_parquet(file.news_articles_cleaned_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_original</th>\n",
       "      <th>label</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>text_tokenized_keywords</th>\n",
       "      <th>text_keywords</th>\n",
       "      <th>text_tokenized_lemmas</th>\n",
       "      <th>text_lemmas</th>\n",
       "      <th>text_tokenized_stemmed</th>\n",
       "      <th>text_stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21-Jähriger fällt wohl bis Saisonende aus. Wie...</td>\n",
       "      <td>Sport</td>\n",
       "      <td>[21-jähriger, fällt, wohl, bis, saisonende, au...</td>\n",
       "      <td>[21-jähriger, fällt, wohl, saisonende, ., wien...</td>\n",
       "      <td>21-jähriger fällt wohl saisonende . wien – rap...</td>\n",
       "      <td>[21-jähriger, fällen, wohl, saisonende, wien, ...</td>\n",
       "      <td>21-jähriger fällen wohl saisonende wien rapid ...</td>\n",
       "      <td>[21-jahrig, fallt, wohl, saison, wien, rapid, ...</td>\n",
       "      <td>21-jahrig fallt wohl saison wien rapid wohl sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Erfundene Bilder zu Filmen, die als verloren g...</td>\n",
       "      <td>Kultur</td>\n",
       "      <td>[erfundene, bilder, zu, filmen, ,, die, als, v...</td>\n",
       "      <td>[erfundene, bilder, filmen, ,, verloren, gelte...</td>\n",
       "      <td>erfundene bilder filmen , verloren gelten : ``...</td>\n",
       "      <td>[erfunden, bilder, filmen, verlieren, gelten, ...</td>\n",
       "      <td>erfunden bilder filmen verlieren gelten `` the...</td>\n",
       "      <td>[erfund, bild, film, verlor, gelt, ``, the, fo...</td>\n",
       "      <td>erfund bild film verlor gelt `` the forbidd ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Der frischgekürte CEO Sundar Pichai setzt auf ...</td>\n",
       "      <td>Web</td>\n",
       "      <td>[der, frischgekürte, ceo, sundar, pichai, setz...</td>\n",
       "      <td>[frischgekürte, ceo, sundar, pichai, setzt, um...</td>\n",
       "      <td>frischgekürte ceo sundar pichai setzt umgängli...</td>\n",
       "      <td>[frischgekürte, ceo, sundar, pichai, setzen, u...</td>\n",
       "      <td>frischgekürte ceo sundar pichai setzen umgängl...</td>\n",
       "      <td>[frischgekurt, ceo, sundar, pichai, setzt, umg...</td>\n",
       "      <td>frischgekurt ceo sundar pichai setzt umgang fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Putin: \"Einigung, dass wir Menge auf Niveau vo...</td>\n",
       "      <td>Wirtschaft</td>\n",
       "      <td>[putin, :, ``, einigung, ,, dass, wir, menge, ...</td>\n",
       "      <td>[putin, :, ``, einigung, ,, menge, niveau, jän...</td>\n",
       "      <td>putin : `` einigung , menge niveau jänner halt...</td>\n",
       "      <td>[putin, ``, einigung, menge, niveau, jänner, h...</td>\n",
       "      <td>putin `` einigung menge niveau jänner halten m...</td>\n",
       "      <td>[putin, ``, einig, meng, niveau, jann, halt, '...</td>\n",
       "      <td>putin `` einig meng niveau jann halt '' moskau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Estland sieht den künftigen österreichischen P...</td>\n",
       "      <td>Inland</td>\n",
       "      <td>[estland, sieht, den, künftigen, österreichisc...</td>\n",
       "      <td>[estland, sieht, künftigen, österreichischen, ...</td>\n",
       "      <td>estland sieht künftigen österreichischen präsi...</td>\n",
       "      <td>[estland, sehen, künftig, österreichisch, präs...</td>\n",
       "      <td>estland sehen künftig österreichisch präsident...</td>\n",
       "      <td>[estland, sieht, kunftig, osterreich, prasiden...</td>\n",
       "      <td>estland sieht kunftig osterreich prasident est...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9240</th>\n",
       "      <td>Bernd Saurer war Bridge-Juniorenweltmeister un...</td>\n",
       "      <td>Inland</td>\n",
       "      <td>[bernd, saurer, war, bridge-juniorenweltmeiste...</td>\n",
       "      <td>[bernd, saurer, bridge-juniorenweltmeister, ,,...</td>\n",
       "      <td>bernd saurer bridge-juniorenweltmeister , krau...</td>\n",
       "      <td>[bernd, sauer, bridge-juniorenweltmeister, kra...</td>\n",
       "      <td>bernd sauer bridge-juniorenweltmeister krauss ...</td>\n",
       "      <td>[bernd, saur, bridge-juniorenweltmeist, krauss...</td>\n",
       "      <td>bernd saur bridge-juniorenweltmeist krauss sch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9241</th>\n",
       "      <td>Sandhere soll in vergangener Woche bei Luftang...</td>\n",
       "      <td>International</td>\n",
       "      <td>[sandhere, soll, in, vergangener, woche, bei, ...</td>\n",
       "      <td>[sandhere, vergangener, woche, luftangriff, ge...</td>\n",
       "      <td>sandhere vergangener woche luftangriff getötet...</td>\n",
       "      <td>[sandhere, vergangen, woche, luftangriff, töte...</td>\n",
       "      <td>sandhere vergangen woche luftangriff töten wer...</td>\n",
       "      <td>[sandh, vergang, woch, luftangriff, getotet, w...</td>\n",
       "      <td>sandh vergang woch luftangriff getotet word wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9242</th>\n",
       "      <td>Derzeit Konzeptgruppe in Berlin – Kein Komment...</td>\n",
       "      <td>Wirtschaft</td>\n",
       "      <td>[derzeit, konzeptgruppe, in, berlin, –, kein, ...</td>\n",
       "      <td>[derzeit, konzeptgruppe, berlin, –, kommentar,...</td>\n",
       "      <td>derzeit konzeptgruppe berlin – kommentar apple...</td>\n",
       "      <td>[derzeit, konzeptgruppe, berlin, kommentar, ap...</td>\n",
       "      <td>derzeit konzeptgruppe berlin kommentar apple m...</td>\n",
       "      <td>[derzeit, konzeptgrupp, berlin, kommentar, app...</td>\n",
       "      <td>derzeit konzeptgrupp berlin kommentar appl mag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9243</th>\n",
       "      <td>Landeshauptmann will den vierten Regierungssit...</td>\n",
       "      <td>Inland</td>\n",
       "      <td>[landeshauptmann, will, den, vierten, regierun...</td>\n",
       "      <td>[landeshauptmann, vierten, regierungssitz, erh...</td>\n",
       "      <td>landeshauptmann vierten regierungssitz erhalte...</td>\n",
       "      <td>[landeshauptmann, viert, regierungssitz, erhal...</td>\n",
       "      <td>landeshauptmann viert regierungssitz erhalten ...</td>\n",
       "      <td>[landeshauptmann, viert, regierungssitz, erhal...</td>\n",
       "      <td>landeshauptmann viert regierungssitz erhalt fp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9244</th>\n",
       "      <td>Er ist einer von Millionen syrischen Flüchtlin...</td>\n",
       "      <td>Panorama</td>\n",
       "      <td>[er, ist, einer, von, millionen, syrischen, fl...</td>\n",
       "      <td>[millionen, syrischen, flüchtlingen, ., kamera...</td>\n",
       "      <td>millionen syrischen flüchtlingen . kamerafrau ...</td>\n",
       "      <td>[millionen, syrisch, flüchtlingen, kamerafrau,...</td>\n",
       "      <td>millionen syrisch flüchtlingen kamerafrau rech...</td>\n",
       "      <td>[million, syrisch, fluchtling, kamerafrau, rec...</td>\n",
       "      <td>million syrisch fluchtling kamerafrau rechtsge...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9245 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          text_original          label  \\\n",
       "0     21-Jähriger fällt wohl bis Saisonende aus. Wie...          Sport   \n",
       "1     Erfundene Bilder zu Filmen, die als verloren g...         Kultur   \n",
       "2     Der frischgekürte CEO Sundar Pichai setzt auf ...            Web   \n",
       "3     Putin: \"Einigung, dass wir Menge auf Niveau vo...     Wirtschaft   \n",
       "4     Estland sieht den künftigen österreichischen P...         Inland   \n",
       "...                                                 ...            ...   \n",
       "9240  Bernd Saurer war Bridge-Juniorenweltmeister un...         Inland   \n",
       "9241  Sandhere soll in vergangener Woche bei Luftang...  International   \n",
       "9242  Derzeit Konzeptgruppe in Berlin – Kein Komment...     Wirtschaft   \n",
       "9243  Landeshauptmann will den vierten Regierungssit...         Inland   \n",
       "9244  Er ist einer von Millionen syrischen Flüchtlin...       Panorama   \n",
       "\n",
       "                                         text_tokenized  \\\n",
       "0     [21-jähriger, fällt, wohl, bis, saisonende, au...   \n",
       "1     [erfundene, bilder, zu, filmen, ,, die, als, v...   \n",
       "2     [der, frischgekürte, ceo, sundar, pichai, setz...   \n",
       "3     [putin, :, ``, einigung, ,, dass, wir, menge, ...   \n",
       "4     [estland, sieht, den, künftigen, österreichisc...   \n",
       "...                                                 ...   \n",
       "9240  [bernd, saurer, war, bridge-juniorenweltmeiste...   \n",
       "9241  [sandhere, soll, in, vergangener, woche, bei, ...   \n",
       "9242  [derzeit, konzeptgruppe, in, berlin, –, kein, ...   \n",
       "9243  [landeshauptmann, will, den, vierten, regierun...   \n",
       "9244  [er, ist, einer, von, millionen, syrischen, fl...   \n",
       "\n",
       "                                text_tokenized_keywords  \\\n",
       "0     [21-jähriger, fällt, wohl, saisonende, ., wien...   \n",
       "1     [erfundene, bilder, filmen, ,, verloren, gelte...   \n",
       "2     [frischgekürte, ceo, sundar, pichai, setzt, um...   \n",
       "3     [putin, :, ``, einigung, ,, menge, niveau, jän...   \n",
       "4     [estland, sieht, künftigen, österreichischen, ...   \n",
       "...                                                 ...   \n",
       "9240  [bernd, saurer, bridge-juniorenweltmeister, ,,...   \n",
       "9241  [sandhere, vergangener, woche, luftangriff, ge...   \n",
       "9242  [derzeit, konzeptgruppe, berlin, –, kommentar,...   \n",
       "9243  [landeshauptmann, vierten, regierungssitz, erh...   \n",
       "9244  [millionen, syrischen, flüchtlingen, ., kamera...   \n",
       "\n",
       "                                          text_keywords  \\\n",
       "0     21-jähriger fällt wohl saisonende . wien – rap...   \n",
       "1     erfundene bilder filmen , verloren gelten : ``...   \n",
       "2     frischgekürte ceo sundar pichai setzt umgängli...   \n",
       "3     putin : `` einigung , menge niveau jänner halt...   \n",
       "4     estland sieht künftigen österreichischen präsi...   \n",
       "...                                                 ...   \n",
       "9240  bernd saurer bridge-juniorenweltmeister , krau...   \n",
       "9241  sandhere vergangener woche luftangriff getötet...   \n",
       "9242  derzeit konzeptgruppe berlin – kommentar apple...   \n",
       "9243  landeshauptmann vierten regierungssitz erhalte...   \n",
       "9244  millionen syrischen flüchtlingen . kamerafrau ...   \n",
       "\n",
       "                                  text_tokenized_lemmas  \\\n",
       "0     [21-jähriger, fällen, wohl, saisonende, wien, ...   \n",
       "1     [erfunden, bilder, filmen, verlieren, gelten, ...   \n",
       "2     [frischgekürte, ceo, sundar, pichai, setzen, u...   \n",
       "3     [putin, ``, einigung, menge, niveau, jänner, h...   \n",
       "4     [estland, sehen, künftig, österreichisch, präs...   \n",
       "...                                                 ...   \n",
       "9240  [bernd, sauer, bridge-juniorenweltmeister, kra...   \n",
       "9241  [sandhere, vergangen, woche, luftangriff, töte...   \n",
       "9242  [derzeit, konzeptgruppe, berlin, kommentar, ap...   \n",
       "9243  [landeshauptmann, viert, regierungssitz, erhal...   \n",
       "9244  [millionen, syrisch, flüchtlingen, kamerafrau,...   \n",
       "\n",
       "                                            text_lemmas  \\\n",
       "0     21-jähriger fällen wohl saisonende wien rapid ...   \n",
       "1     erfunden bilder filmen verlieren gelten `` the...   \n",
       "2     frischgekürte ceo sundar pichai setzen umgängl...   \n",
       "3     putin `` einigung menge niveau jänner halten m...   \n",
       "4     estland sehen künftig österreichisch präsident...   \n",
       "...                                                 ...   \n",
       "9240  bernd sauer bridge-juniorenweltmeister krauss ...   \n",
       "9241  sandhere vergangen woche luftangriff töten wer...   \n",
       "9242  derzeit konzeptgruppe berlin kommentar apple m...   \n",
       "9243  landeshauptmann viert regierungssitz erhalten ...   \n",
       "9244  millionen syrisch flüchtlingen kamerafrau rech...   \n",
       "\n",
       "                                 text_tokenized_stemmed  \\\n",
       "0     [21-jahrig, fallt, wohl, saison, wien, rapid, ...   \n",
       "1     [erfund, bild, film, verlor, gelt, ``, the, fo...   \n",
       "2     [frischgekurt, ceo, sundar, pichai, setzt, umg...   \n",
       "3     [putin, ``, einig, meng, niveau, jann, halt, '...   \n",
       "4     [estland, sieht, kunftig, osterreich, prasiden...   \n",
       "...                                                 ...   \n",
       "9240  [bernd, saur, bridge-juniorenweltmeist, krauss...   \n",
       "9241  [sandh, vergang, woch, luftangriff, getotet, w...   \n",
       "9242  [derzeit, konzeptgrupp, berlin, kommentar, app...   \n",
       "9243  [landeshauptmann, viert, regierungssitz, erhal...   \n",
       "9244  [million, syrisch, fluchtling, kamerafrau, rec...   \n",
       "\n",
       "                                              text_stem  \n",
       "0     21-jahrig fallt wohl saison wien rapid wohl sa...  \n",
       "1     erfund bild film verlor gelt `` the forbidd ro...  \n",
       "2     frischgekurt ceo sundar pichai setzt umgang fu...  \n",
       "3     putin `` einig meng niveau jann halt '' moskau...  \n",
       "4     estland sieht kunftig osterreich prasident est...  \n",
       "...                                                 ...  \n",
       "9240  bernd saur bridge-juniorenweltmeist krauss sch...  \n",
       "9241  sandh vergang woch luftangriff getotet word wa...  \n",
       "9242  derzeit konzeptgrupp berlin kommentar appl mag...  \n",
       "9243  landeshauptmann viert regierungssitz erhalt fp...  \n",
       "9244  million syrisch fluchtling kamerafrau rechtsge...  \n",
       "\n",
       "[9245 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import TextVectorization\n",
    "import fasttext.util\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Conv1D, GlobalMaxPooling1D, InputLayer\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras import Sequential\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "def get_embedder_fasttext(embedding_dim, model_name=\"cc.de.300.bin\"):\n",
    "    split = model_name.split(\".\")\n",
    "    model_lang = split[1]\n",
    "    model_dim = int(split[2])\n",
    "\n",
    "    try:\n",
    "        ft = fasttext.load_model(model_name)\n",
    "    except ValueError:\n",
    "        fasttext.util.download_model(model_lang, if_exists='ignore')\n",
    "        ft = fasttext.load_model(model_name)\n",
    "\n",
    "    if embedding_dim < model_dim:\n",
    "        fasttext.util.reduce_model(ft, embedding_dim)\n",
    "\n",
    "    def fasttext_embedder(word):\n",
    "        return ft.get_word_vector(word)\n",
    "\n",
    "    return fasttext_embedder\n",
    "\n",
    "\n",
    "def calculate_embedding_matrix(vocabulary, embedding_dim=300, verbose=False):\n",
    "    \"\"\"Creates the embedding matrix\n",
    "    \"\"\"\n",
    "    voc_size = len(vocabulary)\n",
    "    words_not_found = set()\n",
    "    embedding_matrix = np.zeros((voc_size, embedding_dim))\n",
    "\n",
    "    embedder = get_embedder_fasttext(embedding_dim)\n",
    "    \n",
    "    \n",
    "    for idx, word in enumerate(vocabulary):\n",
    "        embedding_vector = embedder(word)\n",
    "        if (embedding_vector is not None) and len(embedding_vector) > 0 and not np.all(embedding_vector == 0):\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[idx] = embedding_vector\n",
    "        else:\n",
    "            words_not_found.add(word)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Embedding type: fasttext\")\n",
    "        print(\"Number of null word embeddings:\", np.sum(np.sum(embedding_matrix, axis=1) == 0))\n",
    "        nr_words_not_found = len(words_not_found)\n",
    "        print(\"Words not found in total:\", len(words_not_found))\n",
    "        if nr_words_not_found > 0:\n",
    "            import random\n",
    "\n",
    "            nr_sample = min(20, len(words_not_found))\n",
    "            print(\"Words without embedding (\", nr_sample, \"/\", nr_words_not_found, \"): \",\n",
    "                  random.sample(words_not_found, nr_sample), sep='')\n",
    "\n",
    "    return embedding_matrix\n",
    "\n",
    "\n",
    "def extract_vocabulary_and_set(data, verbose=False):\n",
    "    sequence_length_percentil_cutoff = 0.98\n",
    "    sequence_length_max = 768\n",
    "\n",
    "    vocabulary = set()\n",
    "    _ = data.apply(lambda x: vocabulary.update(x))\n",
    "\n",
    "    lengths = data.apply(len)\n",
    "    max_sequence_length = int(lengths.quantile(1.0))\n",
    "    percentil_sequence_length = int(lengths.quantile(0.98))\n",
    "    median_sequence_length = int(lengths.quantile(0.5))\n",
    "    embedding_sequence_length = min(sequence_length_max, percentil_sequence_length)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Median sequence length:       : {median_sequence_length}\")\n",
    "        print(f\"Percentil                     : {sequence_length_percentil_cutoff})\")\n",
    "        print(f\"Cutoff sequence length        : {percentil_sequence_length}\")\n",
    "        print(f\"Max sequence length           : {max_sequence_length}\")\n",
    "        print(f\"Used embedding sequence length: {embedding_sequence_length}\")\n",
    "        print(f\"Vocabulary length             : {len(vocabulary)}\")\n",
    "\n",
    "    return (vocabulary, embedding_sequence_length)\n",
    "\n",
    "\n",
    "def compile_model(model, loss_function=\"categorical_crossentropy\", learning_rate=0.01, model_metric = [\"accuracy\"]):\n",
    "    adam = Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss=loss_function, optimizer=adam, metrics=model_metric)\n",
    "    \n",
    "    \n",
    "def build_model_cnn_simple(X_train, y_train, conv_num_filters=128, conv_kernel_size=7):\n",
    "\n",
    "    vocabulary, embedding_length = extract_vocabulary_and_set(X_train, verbose=True)\n",
    "    print(f\"embedding length: {embedding_length}\")\n",
    "    \n",
    "    embedding_matrix = calculate_embedding_matrix(vocabulary)\n",
    "    embedding_input_dim, embedding_output_dim = embedding_matrix.shape[0], embedding_matrix.shape[1]\n",
    "    \n",
    "    output_classes = len(y_train.unique())\n",
    "\n",
    "    vectorize_layer = TextVectorization(\n",
    "        output_mode='int',\n",
    "        output_sequence_length=None,\n",
    "        vocabulary=list(vocabulary),\n",
    "        name=\"text_vectorization\"\n",
    "    )\n",
    "\n",
    "    embedding_layer = Embedding(\n",
    "        embedding_input_dim,\n",
    "        embedding_output_dim,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=embedding_length,\n",
    "        trainable=False,\n",
    "        mask_zero=True,\n",
    "        name=\"embedding\"\n",
    "    )\n",
    "\n",
    "\n",
    "    model = Sequential(name=\"cnn\")\n",
    "    model.add(InputLayer(input_shape=(1,), dtype=tf.string, name=\"text_input\"))\n",
    "    model.add(vectorize_layer)\n",
    "    model.add(embedding_layer)\n",
    "    model.add(Conv1D(conv_num_filters, conv_kernel_size, activation=\"relu\", strides=1, padding=\"valid\", name=\"conv_1\"))\n",
    "    model.add(GlobalMaxPooling1D(name=\"global_max_pool_1\"))\n",
    "    model.add(Dense(output_classes, activation=tf.nn.softmax, name=\"prediction\"))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train.text_tokenized_stemmed\n",
    "y_train = data_train.label\n",
    "\n",
    "X_test = data_test.text_tokenized_stemmed\n",
    "y_test = data_test.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median sequence length:       : 173\n",
      "Percentil                     : 0.98)\n",
      "Cutoff sequence length        : 589\n",
      "Max sequence length           : 1699\n",
      "Used embedding sequence length: 589\n",
      "Vocabulary length             : 162207\n",
      "embedding length: 589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "2021-11-01 22:39:03.804389: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-01 22:39:03.830330: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-01 22:39:03.831015: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-01 22:39:03.832271: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-01 22:39:03.832650: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-01 22:39:03.833316: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-01 22:39:03.833882: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-01 22:39:04.259224: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-01 22:39:04.259923: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-01 22:39:04.260581: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-01 22:39:04.261259: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13839 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text_vectorization (TextVect (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 300)         48662100  \n",
      "_________________________________________________________________\n",
      "conv_1 (Conv1D)              (None, None, 128)         268928    \n",
      "_________________________________________________________________\n",
      "global_max_pool_1 (GlobalMax (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "prediction (Dense)           (None, 9)                 1161      \n",
      "=================================================================\n",
      "Total params: 48,932,189\n",
      "Trainable params: 270,089\n",
      "Non-trainable params: 48,662,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model_cnn_simple(X_train, y_train)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "compile_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "y_train = data_train.label\n",
    "label_binarizer = LabelBinarizer()\n",
    "label_binarizer.fit(y_train)\n",
    "\n",
    "x_train = data_train['text_stem']\n",
    "y_train_bin = label_binarizer.transform(y_train)\n",
    "\n",
    "x_test = data_test['text_stem']\n",
    "y_test_bin = label_binarizer.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None,), (None, 9)), types: (tf.string, tf.int64)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input = tf.data.Dataset.from_tensor_slices((x_train, y_train_bin)).batch(128).prefetch(tf.data.AUTOTUNE)\n",
    "test_input = tf.data.Dataset.from_tensor_slices((x_test, y_test_bin)).batch(128).prefetch(tf.data.AUTOTUNE)\n",
    "train_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-01 22:39:07.686973: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-11-01 22:39:07.687016: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2021-11-01 22:39:07.687068: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1614] Profiler found 1 GPUs\n",
      "2021-11-01 22:39:07.864568: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2021-11-01 22:39:07.864818: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1748] CUPTI activity buffer flushed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-01 22:39:11.142301: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-01 22:39:12.327761: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/73 [..............................] - ETA: 17:51 - loss: 2.2243 - accuracy: 0.1250"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-01 22:39:24.186268: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-11-01 22:39:24.186305: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/73 [..............................] - ETA: 1:04 - loss: 2.2462 - accuracy: 0.1445 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-01 22:39:25.085424: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2021-11-01 22:39:25.085947: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1748] CUPTI activity buffer flushed\n",
      "2021-11-01 22:39:25.216828: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 343 callback api events and 290 activity events. \n",
      "2021-11-01 22:39:25.224672: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2021-11-01 22:39:25.258889: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/fit/train/plugins/profile/2021_11_01_22_39_25\n",
      "\n",
      "2021-11-01 22:39:25.265684: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to logs/fit/train/plugins/profile/2021_11_01_22_39_25/iowa-tf-26-cpu-2-gpu-1.trace.json.gz\n",
      "2021-11-01 22:39:25.284179: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/fit/train/plugins/profile/2021_11_01_22_39_25\n",
      "\n",
      "2021-11-01 22:39:25.285574: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to logs/fit/train/plugins/profile/2021_11_01_22_39_25/iowa-tf-26-cpu-2-gpu-1.memory_profile.json.gz\n",
      "2021-11-01 22:39:25.286337: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/fit/train/plugins/profile/2021_11_01_22_39_25\n",
      "Dumped tool data for xplane.pb to logs/fit/train/plugins/profile/2021_11_01_22_39_25/iowa-tf-26-cpu-2-gpu-1.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs/fit/train/plugins/profile/2021_11_01_22_39_25/iowa-tf-26-cpu-2-gpu-1.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/fit/train/plugins/profile/2021_11_01_22_39_25/iowa-tf-26-cpu-2-gpu-1.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/fit/train/plugins/profile/2021_11_01_22_39_25/iowa-tf-26-cpu-2-gpu-1.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/fit/train/plugins/profile/2021_11_01_22_39_25/iowa-tf-26-cpu-2-gpu-1.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 55s 562ms/step - loss: 1.8467 - accuracy: 0.3465 - val_loss: 1.5661 - val_accuracy: 0.4504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-01 22:40:05.309840: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 11678904000 exceeds 10% of free system memory.\n",
      "2021-11-01 22:40:05.309940: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at one_hot_op.cc:97 : Resource exhausted: OOM when allocating tensor with shape[48662100,30] and type double on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[48662100,30] and type double on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:OneHot]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9497/305957690.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"logs/fit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistogram_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1228\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1230\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1231\u001b[0m         \u001b[0mtraining_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m       \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   2445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2446\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram_freq\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2447\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2449\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_freq\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_log_weights\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m   2512\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2513\u001b[0m             \u001b[0mweight_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m':'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2514\u001b[0;31m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2516\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_weight_as_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorboard/plugins/histogram/summary_v2.py\u001b[0m in \u001b[0;36mhistogram\u001b[0;34m(name, data, step, buckets, description)\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         )\n\u001b[0;32m--> 178\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistogram_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuckets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_metadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorboard/plugins/histogram/summary_v2.py\u001b[0m in \u001b[0;36mhistogram_summary\u001b[0;34m(data, buckets, histogram_metadata, step)\u001b[0m\n\u001b[1;32m    156\u001b[0m                     \u001b[0mtensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlazy_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                     \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                     \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msummary_metadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m                 )\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(tag, tensor, step, metadata, name)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     op = smart_cond.smart_cond(\n\u001b[0;32m--> 763\u001b[0;31m         should_record_summaries(), record, _nothing, name=\"summary_cond\")\n\u001b[0m\u001b[1;32m    764\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/smart_cond.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpred_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpred_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py\u001b[0m in \u001b[0;36mrecord\u001b[0;34m()\u001b[0m\n\u001b[1;32m    748\u001b[0m       \u001b[0;31m# Note the identity to move the tensor to the CPU.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m         summary_tensor = tensor() if callable(tensor) else array_ops.identity(\n\u001b[0m\u001b[1;32m    751\u001b[0m             tensor)\n\u001b[1;32m    752\u001b[0m         write_summary_op = gen_summary_ops.write_summary(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorboard/util/lazy_tensor_creator.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_CALL_IN_PROGRESS_SENTINEL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorboard/plugins/histogram/summary_v2.py\u001b[0m in \u001b[0;36mlazy_tensor\u001b[0;34m()\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0;34m@\u001b[0m\u001b[0mlazy_tensor_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLazyTensorCreator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0;32mdef\u001b[0m \u001b[0mlazy_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0m_buckets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuckets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                 return tf.summary.write(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorboard/plugins/histogram/summary_v2.py\u001b[0m in \u001b[0;36m_buckets\u001b[0;34m(data, bucket_count)\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_singular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhen_singular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhen_nonsingular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_empty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhen_empty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhen_nonempty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mcond_for_tf_v2\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m   1436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1437\u001b[0m   \"\"\"\n\u001b[0;32m-> 1438\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrue_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfalse_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m                 instructions)\n\u001b[0;32m--> 549\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mcond\u001b[0;34m(pred, true_fn, false_fn, strict, name, fn1, fn2)\u001b[0m\n\u001b[1;32m   1248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eager_cond_implementation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m   \u001b[0;31m# Always enable control flow v2 if building a function, regardless of toggle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m_eager_cond_implementation\u001b[0;34m(pred, true_fn, false_fn, strict, name)\u001b[0m\n\u001b[1;32m   1139\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1142\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_UnpackIfSingleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorboard/plugins/histogram/summary_v2.py\u001b[0m in \u001b[0;36mwhen_nonempty\u001b[0;34m()\u001b[0m\n\u001b[1;32m    246\u001b[0m                 )\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_singular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhen_singular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhen_nonsingular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_empty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhen_empty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhen_nonempty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mcond_for_tf_v2\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m   1436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1437\u001b[0m   \"\"\"\n\u001b[0;32m-> 1438\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrue_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfalse_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m                 instructions)\n\u001b[0;32m--> 549\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mcond\u001b[0;34m(pred, true_fn, false_fn, strict, name, fn1, fn2)\u001b[0m\n\u001b[1;32m   1248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eager_cond_implementation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m   \u001b[0;31m# Always enable control flow v2 if building a function, regardless of toggle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m_eager_cond_implementation\u001b[0;34m(pred, true_fn, false_fn, strict, name)\u001b[0m\n\u001b[1;32m   1139\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1142\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_UnpackIfSingleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorboard/plugins/histogram/summary_v2.py\u001b[0m in \u001b[0;36mwhen_nonsingular\u001b[0;34m()\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0;31m# See https://github.com/tensorflow/tensorflow/issues/51419 for details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 one_hots = tf.one_hot(\n\u001b[0;32m--> 221\u001b[0;31m                     \u001b[0mclamped_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbucket_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m                 )\n\u001b[1;32m    223\u001b[0m                 bucket_counts = tf.cast(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mone_hot\u001b[0;34m(indices, depth, on_value, off_value, axis, dtype, name)\u001b[0m\n\u001b[1;32m   4348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4349\u001b[0m     return gen_array_ops.one_hot(indices, depth, on_value, off_value, axis,\n\u001b[0;32m-> 4350\u001b[0;31m                                  name)\n\u001b[0m\u001b[1;32m   4351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mone_hot\u001b[0;34m(indices, depth, on_value, off_value, axis, name)\u001b[0m\n\u001b[1;32m   6237\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6238\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6239\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6240\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6241\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6939\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6940\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6941\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6942\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[48662100,30] and type double on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:OneHot]"
     ]
    }
   ],
   "source": [
    "#%tensorboard --logdir logs/fit\n",
    "\n",
    "callbacks = [TensorBoard(\"logs/fit\", histogram_freq=1)]\n",
    "history = model.fit(train_input, validation_data=test_input, callbacks=callbacks, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m82",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m82"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
